{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assigment, we will work with the *Forest Fire* data set. Please download the data from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/162/forest+fires). Extract the data files into the subdirectory: `../data/fires/` (relative to `./05_src/`).\n",
    "\n",
    "## Objective\n",
    "\n",
    "+ The model objective is to predict the area affected by forest fires given the features set. \n",
    "+ The objective of this exercise is to assess your ability to construct and evaluate model pipelines.\n",
    "+ Please note: the instructions are not meant to be 100% prescriptive, but instead they are a set of minimum requirements. If you find predictive performance gains by applying additional steps, by all means show them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Description\n",
    "\n",
    "From the description file contained in the archive (`forestfires.names`), we obtain the following variable descriptions:\n",
    "\n",
    "1. X - x-axis spatial coordinate within the Montesinho park map: 1 to 9\n",
    "2. Y - y-axis spatial coordinate within the Montesinho park map: 2 to 9\n",
    "3. month - month of the year: \"jan\" to \"dec\" \n",
    "4. day - day of the week: \"mon\" to \"sun\"\n",
    "5. FFMC - FFMC index from the FWI system: 18.7 to 96.20\n",
    "6. DMC - DMC index from the FWI system: 1.1 to 291.3 \n",
    "7. DC - DC index from the FWI system: 7.9 to 860.6 \n",
    "8. ISI - ISI index from the FWI system: 0.0 to 56.10\n",
    "9. temp - temperature in Celsius degrees: 2.2 to 33.30\n",
    "10. RH - relative humidity in %: 15.0 to 100\n",
    "11. wind - wind speed in km/h: 0.40 to 9.40 \n",
    "12. rain - outside rain in mm/m2 : 0.0 to 6.4 \n",
    "13. area - the burned area of the forest (in ha): 0.00 to 1090.84 \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Specific Tasks\n",
    "\n",
    "+ Construct four model pipelines, out of combinations of the following components:\n",
    "\n",
    "    + Preprocessors:\n",
    "\n",
    "        - A simple processor that only scales numeric variables and recodes categorical variables.\n",
    "        - A transformation preprocessor that scales numeric variables and applies a non-linear transformation.\n",
    "    \n",
    "    + Regressor:\n",
    "\n",
    "        - A baseline regressor, which could be a [K-nearest neighbours model]() or a linear model like [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) or [Ridge Regressors](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ridge_regression.html).\n",
    "        - An advanced regressor of your choice (e.g., Bagging, Boosting, SVR, etc.). TIP: select a tree-based method such that it does not take too long to run SHAP further below. \n",
    "\n",
    "+ Evaluate tune and evaluate each of the four model pipelines. \n",
    "\n",
    "    - Select a [performance metric](https://scikit-learn.org/stable/modules/linear_model.html) out of the following options: explained variance, max error, root mean squared error (RMSE), mean absolute error (MAE), r-squared.\n",
    "    - *TIPS*: \n",
    "    \n",
    "        * Out of the suggested metrics above, [some are correlation metrics, but this is a prediction problem](https://www.tmwr.org/performance#performance). Choose wisely (and don't choose the incorrect options.) \n",
    "\n",
    "+ Select the best-performing model and explain its predictions.\n",
    "\n",
    "    - Provide local explanations.\n",
    "    - Obtain global explanations and recommend a variable selection strategy.\n",
    "\n",
    "+ Export your model as a pickle file.\n",
    "\n",
    "\n",
    "You can work on the Jupyter notebook, as this experiment is fairly short (no need to use sacred). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "\n",
    "Place the files in the ../../05_src/data/fires/ directory and load the appropriate file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler #, RobustScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "columns = [\n",
    "    'coord_x', 'coord_y', 'month', 'day', 'ffmc', 'dmc', 'dc', 'isi', 'temp', 'rh', 'wind', 'rain', 'area' \n",
    "]\n",
    "fires_dt = (pd.read_csv('../../05_src/data/fires/forestfires.csv', header = 0, names = columns))\n",
    "fires_dt.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get X and Y\n",
    "\n",
    "Create the features data frame and target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fires_dt.drop('area', axis=1)\n",
    "y = fires_dt['area']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)\n",
    "\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# month_categories = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', \n",
    "                #    'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "# day_categories = ['mon', 'tue', 'wed', 'thu', 'fri', 'sat', 'sun']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Create two [Column Transformers](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html), called preproc1 and preproc2, with the following guidelines:\n",
    "\n",
    "- Numerical variables\n",
    "\n",
    "    * (Preproc 1 and 2) Scaling: use a scaling method of your choice (Standard, Robust, Min-Max). \n",
    "    * Preproc 2 only: \n",
    "        \n",
    "        + Choose a transformation for any of your input variables (or several of them). Evaluate if this transformation is convenient.\n",
    "        + The choice of scaler is up to you.\n",
    "\n",
    "- Categorical variables: \n",
    "    \n",
    "    * (Preproc 1 and 2) Apply [one-hot encoding](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) where appropriate.\n",
    "\n",
    "\n",
    "+ The only difference between preproc1 and preproc2 is the non-linear transformation of the numerical variables.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preproc 1\n",
    "\n",
    "Create preproc1 below.\n",
    "\n",
    "+ Numeric: scaled variables, no other transforms.\n",
    "+ Categorical: one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV (and fires_dt.info()) shows that all the featues except day and month are numeric\n",
    "numeric_features = ['coord_x', 'coord_y', 'ffmc', 'dmc', 'dc', 'isi', 'temp', 'rh', 'wind', 'rain']\n",
    "# And categorical features are respectively:\n",
    "categorical_features = ['month', 'day']\n",
    "\n",
    "# preproc1 = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('numeric', StandardScaler(), numeric_features),\n",
    "#         ('categorical', OneHotEncoder(drop='first', sparse_output=False), categorical_features)\n",
    "#     ],\n",
    "#     remainder='passthrough'\n",
    "#     # remainder='drop'\n",
    "# )\n",
    "\n",
    "preproc1 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric', StandardScaler(), numeric_features),\n",
    "        ('categorical', OneHotEncoder(\n",
    "            drop='first', \n",
    "            sparse_output=False,\n",
    "            categories=[month_categories, day_categories]\n",
    "        ), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "preproc1\n",
    "# preproc1.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine distributions of numeric features\n",
    "fig, axes = plt.subplots(5, 2, figsize=(15, 20))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(numeric_features):\n",
    "    sns.histplot(data=fires_dt, x=col, ax=axes[idx])\n",
    "    axes[idx].set_title(f'Distribution of {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Skewness values\n",
    "skewness = fires_dt[numeric_features].skew()\n",
    "print(\"\\nSkewness of numeric features:\")\n",
    "print(skewness)\n",
    "\n",
    "# Show how transformations affect data\n",
    "example_feature = fires_dt['dmc']  # highly skewed feature\n",
    "\n",
    "print(\"Original DMC statistics:\")\n",
    "print(example_feature.describe())\n",
    "\n",
    "print(\"\\nLog-transformed DMC statistics:\")\n",
    "print(np.log1p(example_feature).describe())\n",
    "\n",
    "print(\"\\nPower-transformed DMC statistics:\")\n",
    "print(np.power(example_feature, 2).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preproc 2\n",
    "\n",
    "Create preproc2 below.\n",
    "\n",
    "+ Numeric: scaled variables, non-linear transformation to one or more variables.\n",
    "+ Categorical: one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.compose import make_column_transformer\n",
    "# from sklearn.preprocessing import FunctionTransformer\n",
    "# import numpy as np\n",
    "\n",
    "# Create custom transformers for non-linear transformations\n",
    "log_transformer = FunctionTransformer(func=np.log1p)  # log1p handles zero values\n",
    "power_transformer = FunctionTransformer(func=lambda x: np.power(x, 2))\n",
    "\n",
    "# Split numeric features into groups based on their distribution\n",
    "# These features are highly skewed, so we'll apply log transformation\n",
    "log_features = ['dmc', 'dc', 'isi']\n",
    "# These features might benefit from power transformation\n",
    "power_features = ['wind', 'rain']\n",
    "# Rest of numeric features will just be scaled\n",
    "regular_features = ['coord_x', 'coord_y', 'ffmc', 'temp', 'rh']\n",
    "\n",
    "# preproc2 = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         # Regular scaling for some numeric features\n",
    "#         ('scale', StandardScaler(), regular_features),\n",
    "#         # Log transform followed by scaling for skewed features\n",
    "#         ('log', Pipeline([\n",
    "#             ('log', log_transformer),\n",
    "#             ('scale', StandardScaler())\n",
    "#         ]), log_features),\n",
    "#         # Power transform followed by scaling for other features\n",
    "#         ('power', Pipeline([\n",
    "#             ('power', power_transformer),\n",
    "#             ('scale', StandardScaler())\n",
    "#         ]), power_features),\n",
    "#         # One-hot encoding for categorical features\n",
    "#         ('categorical', OneHotEncoder(drop='first', sparse_output=False), categorical_features)\n",
    "#     ],\n",
    "#     remainder='passthrough'\n",
    "#     # remainder='drop'\n",
    "# )\n",
    "preproc2 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scale', StandardScaler(), regular_features),\n",
    "        ('log', Pipeline([\n",
    "            ('log', log_transformer),\n",
    "            ('scale', StandardScaler())\n",
    "        ]), log_features),\n",
    "        ('power', Pipeline([\n",
    "            ('power', power_transformer),\n",
    "            ('scale', StandardScaler())\n",
    "        ]), power_features),\n",
    "        ('cat', OneHotEncoder(\n",
    "            drop='first', \n",
    "            sparse_output=False,\n",
    "            categories=[month_categories, day_categories]\n",
    "        ), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Verify the transformation works\n",
    "preproc2\n",
    "# preproc2.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Pipeline\n",
    "\n",
    "\n",
    "Create a [model pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html): \n",
    "\n",
    "+ Add a step labelled `preprocessing` and assign the Column Transformer from the previous section.\n",
    "+ Add a step labelled `regressor` and assign a regression model to it. \n",
    "\n",
    "## Regressor\n",
    "\n",
    "+ Use a regression model to perform a prediction. \n",
    "\n",
    "    - Choose a baseline regressor, tune it (if necessary) using grid search, and evaluate it using cross-validation.\n",
    "    - Choose a more advance regressor, tune it (if necessary) using grid search, and evaluate it using cross-validation.\n",
    "    - Both model choices are up to you, feel free to experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline A = preproc1 + baseline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Pipeline A = preproc1 + baseline (using Ridge as baseline)\n",
    "pipeline_A = Pipeline([\n",
    "    ('preprocessing', preproc1),\n",
    "    ('regressor', Ridge(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline B = preproc2 + baseline\n",
    "\n",
    "pipeline_B = Pipeline([\n",
    "    ('preprocessing', preproc2),\n",
    "    ('regressor', Ridge(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline C = preproc1 + advanced model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "pipeline_C = Pipeline([\n",
    "    ('preprocessing', preproc1),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline D = preproc2 + advanced model\n",
    "\n",
    "pipeline_D = Pipeline([\n",
    "    ('preprocessing', preproc2),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Hyperparams\n",
    "\n",
    "+ Perform GridSearch on each of the four pipelines. \n",
    "+ Tune at least one hyperparameter per pipeline.\n",
    "+ Experiment with at least four value combinations per pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "# Create RMSE scorer\n",
    "rmse_scorer = make_scorer(lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred)))\n",
    "\n",
    "# Parameter grid for Ridge pipelines (A and B)\n",
    "ridge_param_grid = {\n",
    "    'regressor__alpha': [0.1, 1.0, 10.0, 100.0],\n",
    "    'regressor__solver': ['auto', 'svd', 'cholesky']\n",
    "}\n",
    "\n",
    "# Parameter grid for Random Forest pipelines (C and D)\n",
    "rf_param_grid = {\n",
    "    'regressor__n_estimators': [100, 200],\n",
    "    'regressor__max_depth': [10, 20, None],\n",
    "    'regressor__min_samples_split': [2, 5]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune Pipeline A\n",
    "grid_A = GridSearchCV(\n",
    "    pipeline_A, \n",
    "    ridge_param_grid,\n",
    "    cv=5,\n",
    "    scoring=rmse_scorer,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_A.fit(X_train, y_train)\n",
    "print(\"Best parameters for Pipeline A:\", grid_A.best_params_)\n",
    "print(\"Best RMSE score for Pipeline A:\", -grid_A.best_score_)  # Negative because of scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune Pipeline B\n",
    "grid_B = GridSearchCV(\n",
    "    pipeline_B, \n",
    "    ridge_param_grid,\n",
    "    cv=5,\n",
    "    scoring=rmse_scorer,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_B.fit(X_train, y_train)\n",
    "print(\"\\nBest parameters for Pipeline B:\", grid_B.best_params_)\n",
    "print(\"Best RMSE score for Pipeline B:\", -grid_B.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune Pipeline C\n",
    "grid_C = GridSearchCV(\n",
    "    pipeline_C, \n",
    "    rf_param_grid,\n",
    "    cv=5,\n",
    "    scoring=rmse_scorer,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_C.fit(X_train, y_train)\n",
    "print(\"\\nBest parameters for Pipeline C:\", grid_C.best_params_)\n",
    "print(\"Best RMSE score for Pipeline C:\", -grid_C.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune Pipeline D\n",
    "grid_D = GridSearchCV(\n",
    "    pipeline_D, \n",
    "    rf_param_grid,\n",
    "    cv=5,\n",
    "    scoring=rmse_scorer,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_D.fit(X_train, y_train)\n",
    "print(\"\\nBest parameters for Pipeline D:\", grid_D.best_params_)\n",
    "print(\"Best RMSE score for Pipeline D:\", -grid_D.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "\n",
    "+ Which model has the best performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    \n",
    "    # Calculate R2 (for additional insight)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Train RMSE': train_rmse,\n",
    "        'Test RMSE': test_rmse,\n",
    "        'Train R2': train_r2,\n",
    "        'Test R2': test_r2\n",
    "    }\n",
    "\n",
    "# Evaluate all models\n",
    "results = []\n",
    "results.append(evaluate_model(grid_A.best_estimator_, X_train, X_test, y_train, y_test, 'Pipeline A (Preproc1 + Ridge)'))\n",
    "results.append(evaluate_model(grid_B.best_estimator_, X_train, X_test, y_train, y_test, 'Pipeline B (Preproc2 + Ridge)'))\n",
    "results.append(evaluate_model(grid_C.best_estimator_, X_train, X_test, y_train, y_test, 'Pipeline C (Preproc1 + RF)'))\n",
    "results.append(evaluate_model(grid_D.best_estimator_, X_train, X_test, y_train, y_test, 'Pipeline D (Preproc2 + RF)'))\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display results\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Visualize RMSE comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "models = results_df['Model']\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, results_df['Train RMSE'], width, label='Train RMSE')\n",
    "plt.bar(x + width/2, results_df['Test RMSE'], width, label='Test RMSE')\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('RMSE (hectares)')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.xticks(x, models, rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find best model\n",
    "best_idx = results_df['Test RMSE'].idxmin()\n",
    "best_model = results_df.iloc[best_idx]\n",
    "print(f\"\\nBest performing model: {best_model['Model']}\")\n",
    "print(f\"Best Test RMSE: {best_model['Test RMSE']:.2f} hectares\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export\n",
    "\n",
    "+ Save the best performing model to a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Get the best model object based on the evaluation results\n",
    "best_idx = results_df['Test RMSE'].idxmin()\n",
    "best_model_name = results_df.iloc[best_idx]['Model']\n",
    "\n",
    "# Map model name to corresponding GridSearchCV object\n",
    "model_map = {\n",
    "    'Pipeline A (Preproc1 + Ridge)': grid_A,\n",
    "    'Pipeline B (Preproc2 + Ridge)': grid_B,\n",
    "    'Pipeline C (Preproc1 + RF)': grid_C,\n",
    "    'Pipeline D (Preproc2 + RF)': grid_D\n",
    "}\n",
    "\n",
    "best_model = model_map[best_model_name].best_estimator_\n",
    "\n",
    "# Save the model\n",
    "model_filename = '../../05_src/models/best_forest_fire_model.pkl'\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs(os.path.dirname(model_filename), exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "\n",
    "print(f\"Best model ({best_model_name}) has been saved to {model_filename}\")\n",
    "\n",
    "# Verify we can load it back\n",
    "with open(model_filename, 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "    \n",
    "# Test the loaded model\n",
    "test_pred = loaded_model.predict(X_test[:1])\n",
    "print(\"\\nVerification - Prediction for first test sample:\")\n",
    "print(f\"Original model prediction: {best_model.predict(X_test[:1])[0]:.2f}\")\n",
    "print(f\"Loaded model prediction: {test_pred[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain\n",
    "\n",
    "+ Use SHAP values to explain the following only for the best-performing model:\n",
    "\n",
    "    - Select an observation in your test set and explain which are the most important features that explain that observation's specific prediction.\n",
    "\n",
    "    - In general, across the complete training set, which features are the most and least important.\n",
    "\n",
    "+ If you were to remove features from the model, which ones would you remove? Why? How would you test that these features are actually enhancing model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Transform the data first\n",
    "X_train_transformed = best_model.named_steps['preprocessing'].transform(X_train)\n",
    "X_test_transformed = best_model.named_steps['preprocessing'].transform(X_test)\n",
    "\n",
    "# Create the SHAP explainer based on model type\n",
    "if 'RandomForestRegressor' in str(best_model.named_steps['regressor']):\n",
    "    explainer = shap.TreeExplainer(best_model.named_steps['regressor'])\n",
    "else:\n",
    "    # For Ridge regression\n",
    "    explainer = shap.LinearExplainer(best_model.named_steps['regressor'], \n",
    "                                   X_train_transformed)\n",
    "\n",
    "# Calculate SHAP values for test set\n",
    "shap_values = explainer.shap_values(X_test_transformed)\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "if hasattr(best_model.named_steps['preprocessing'], 'get_feature_names_out'):\n",
    "    feature_names = best_model.named_steps['preprocessing'].get_feature_names_out()\n",
    "else:\n",
    "    # If get_feature_names_out is not available, create generic feature names\n",
    "    feature_names = [f'feature_{i}' for i in range(X_train_transformed.shape[1])]\n",
    "\n",
    "# 1. Local Explanation\n",
    "print(\"Local Explanation for the First Test Sample:\")\n",
    "sample_idx = 0\n",
    "print(f\"Actual area: {y_test.iloc[sample_idx]:.2f}\")\n",
    "print(f\"Predicted area: {best_model.predict(X_test.iloc[[sample_idx]])[0]:.2f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.waterfall_plot(shap.Explanation(\n",
    "    values=shap_values[sample_idx],\n",
    "    base_values=explainer.expected_value,\n",
    "    feature_names=feature_names\n",
    "), max_display=10)\n",
    "plt.title(\"Feature Contributions for Single Prediction\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Global Feature Importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values, X_test_transformed, \n",
    "                 feature_names=feature_names,\n",
    "                 plot_type=\"bar\",\n",
    "                 max_display=10)\n",
    "plt.title(\"Global Feature Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display feature importance\n",
    "feature_importance = np.abs(shap_values).mean(axis=0)\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importance\n",
    "})\n",
    "importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(importance_df.head(10).to_string(index=False))\n",
    "\n",
    "# Feature selection recommendation\n",
    "threshold = importance_df['Importance'].mean()\n",
    "features_to_remove = importance_df[importance_df['Importance'] < threshold]\n",
    "print(\"\\nFeatures that could potentially be removed (below average importance):\")\n",
    "print(features_to_remove['Feature'].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# 1. First, let's select a single observation to explain\n",
    "sample_idx = 0\n",
    "sample_observation = X_test.iloc[[sample_idx]]\n",
    "actual_value = y_test.iloc[sample_idx]\n",
    "predicted_value = best_model.predict(sample_observation)[0]\n",
    "\n",
    "print(f\"Analyzing prediction for observation {sample_idx}:\")\n",
    "print(f\"Actual area: {actual_value:.2f} hectares\")\n",
    "print(f\"Predicted area: {predicted_value:.2f} hectares\")\n",
    "print(\"\\nFeature values for this observation:\")\n",
    "for col in sample_observation.columns:\n",
    "    print(f\"{col}: {sample_observation[col].values[0]}\")\n",
    "\n",
    "# 2. Create SHAP explainer and get values\n",
    "X_train_transformed = best_model.named_steps['preprocessing'].transform(X_train)\n",
    "X_test_transformed = best_model.named_steps['preprocessing'].transform(X_test)\n",
    "\n",
    "if 'RandomForestRegressor' in str(best_model.named_steps['regressor']):\n",
    "    explainer = shap.TreeExplainer(best_model.named_steps['regressor'])\n",
    "else:\n",
    "    explainer = shap.LinearExplainer(best_model.named_steps['regressor'], X_train_transformed)\n",
    "\n",
    "shap_values = explainer.shap_values(X_test_transformed)\n",
    "\n",
    "# 3. Get feature names\n",
    "if hasattr(best_model.named_steps['preprocessing'], 'get_feature_names_out'):\n",
    "    feature_names = best_model.named_steps['preprocessing'].get_feature_names_out()\n",
    "else:\n",
    "    feature_names = [f'feature_{i}' for i in range(X_train_transformed.shape[1])]\n",
    "\n",
    "# 4. Local explanation (waterfall plot)\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.waterfall_plot(shap.Explanation(\n",
    "    values=shap_values[sample_idx],\n",
    "    base_values=explainer.expected_value,\n",
    "    feature_names=feature_names\n",
    "), max_display=10)\n",
    "plt.title(\"Local Feature Importance (Single Prediction)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Global feature importance (summary plot)\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values, X_test_transformed, \n",
    "                 feature_names=feature_names,\n",
    "                 plot_type=\"bar\",\n",
    "                 max_display=10)\n",
    "plt.title(\"Global Feature Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Calculate and rank feature importance\n",
    "feature_importance = np.abs(shap_values).mean(axis=0)\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importance\n",
    "})\n",
    "importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance Ranking:\")\n",
    "print(importance_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(Answer here.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criteria\n",
    "\n",
    "The [rubric](./assignment_2_rubric_clean.xlsx) contains the criteria for assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Information\n",
    "\n",
    "ðŸš¨ **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** ðŸš¨ for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "### Submission Parameters:\n",
    "* Submission Due Date: `HH:MM AM/PM - DD/MM/YYYY`\n",
    "* The branch name for your repo should be: `assignment-2`\n",
    "* What to submit for this assignment:\n",
    "    * This Jupyter Notebook (assignment_2.ipynb) should be populated and should be the only change in your pull request.\n",
    "* What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/production/pull/<pr_id>`\n",
    "    * Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "Checklist:\n",
    "- [ ] Created a branch with the correct naming convention.\n",
    "- [ ] Ensured that the repository is public.\n",
    "- [ ] Reviewed the PR description guidelines and adhered to them.\n",
    "- [ ] Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack at the `help` channel. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "Cortez,Paulo and Morais,Anbal. (2008). Forest Fires. UCI Machine Learning Repository. https://doi.org/10.24432/C5D88D."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
